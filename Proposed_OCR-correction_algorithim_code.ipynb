{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Spelling Correction Algorithm for Detecting and Tracking Errors# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, csv\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "\n",
    "#WORDS = Counter(words(open('/home/niddal/Desktop/PhD_projects/Projects/Text_classification/Adversarial_attack/Wikicorpus.txt').read()))\n",
    "WORDS = Counter(words(open('/home/niddal/Desktop/PhD_projects/Projects/Text_classification/Adversarial_attack/blog_test.txt').read()))\n",
    "\n",
    "\n",
    "def P(word, N=sum(WORDS.values())):\n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "\n",
    "def correction(word):\n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "\n",
    "\n",
    "def decode(word):\n",
    "    letters_map = {'@': 'a', '$': 's', '!': 'i', '1': 'l', '0': 'o', '(': 'c', '+': 't'}\n",
    "    symbol_chars = 0\n",
    "    word = list(word.lower())\n",
    "    for i in range(len(word)):\n",
    "        if word[i] in letters_map:\n",
    "            word[i] = letters_map.get(word[i])\n",
    "            symbol_chars += 1\n",
    "    return ''.join(word), symbol_chars\n",
    "\n",
    "\n",
    "def deleteDuplicates(word):\n",
    "    dups_dictionary = {word: 0}\n",
    "    splits = [(word[:i], word[i:]) for i in range(1, len(word))]\n",
    "    deletes = [L + R[1:] for L, R in splits if L[-1] == R[0]]\n",
    "    if len(deletes) > 0:\n",
    "        repeated_chars = 1\n",
    "        dups_dictionary[deletes[0]] = repeated_chars\n",
    "        # Try to remove any other duplicates like removing other o's in shooow\n",
    "        while len(deletes) > 1:\n",
    "            word = list(set(deletes))[0]\n",
    "            splits = [(word[:i], word[i:]) for i in range(1, len(word))]\n",
    "            deletes = [L + R[1:] for L, R in splits if L[-1] == R[0]]\n",
    "            repeated_chars += 1\n",
    "            dups_dictionary[deletes[0]] = repeated_chars\n",
    "        return dups_dictionary\n",
    "    return None\n",
    "\n",
    "\n",
    "def transpose(word):\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "    return transposes\n",
    "\n",
    "\n",
    "def candidates(word):\n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return known([word]) or known(edits1(word)) or known(edits2(word)) or [word]\n",
    "\n",
    "\n",
    "def known(words):\n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "\n",
    "def edits2(word):\n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "\n",
    "def correct_text(text):\n",
    "    if len(text.split(' ')) > 1:\n",
    "        print('Start of words in \"{}\"'.format(text))\n",
    "        for w in text.split(' '):\n",
    "            print('***',end='')\n",
    "            correct_word(w)\n",
    "        print('End of words in \"{}\"'.format(text))\n",
    "    else:\n",
    "        correct_word(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_word(word):\n",
    "    original_word = word.lower()\n",
    "    correction_dictionary = {'Original_word': original_word, 'correction':'',\n",
    "                             'symbol_chars': 0, 'repeated_chars': 0, 'swap_chars': 0, 'OOV': 0}\n",
    "    \n",
    "        #Search if the input is exist in the dictionary\n",
    "    if original_word in WORDS:\n",
    "        correction_dictionary['correction'] = original_word\n",
    "        return correction_dictionary\n",
    "    \n",
    "    #Check if the input is a number\n",
    "    if original_word.isdigit():\n",
    "        correction_dictionary['correction'] = original_word\n",
    "        return correction_dictionary\n",
    "    else:\n",
    "        word = original_word\n",
    "    \n",
    "    # Search for symbols, decode them and try correction on decoded word\n",
    "    decoded_word, symbols_count = decode(word)\n",
    "    if symbols_count > 0:\n",
    "        # Try correction after decode\n",
    "        correction_dictionary['symbol_chars'] += symbols_count\n",
    "        if correction(decoded_word) == decoded_word and decoded_word in WORDS:\n",
    "            #correction_dictionary['symbol_chars'] += symbols_count\n",
    "            correction_dictionary['correction'] = decoded_word\n",
    "            return correction_dictionary\n",
    "        # If we still didn't get a match after decode,\n",
    "        # then we will use the decoded word for more analysis\n",
    "        else:\n",
    "            word = decoded_word\n",
    "\n",
    "    # Try deleteDuplicates\n",
    "    if deleteDuplicates(word):\n",
    "        duplicates_dictionary = deleteDuplicates(word)\n",
    "        for trimmed_word in duplicates_dictionary:\n",
    "            if correction(trimmed_word) == trimmed_word and trimmed_word in WORDS:\n",
    "                correction_dictionary['repeated_chars'] += duplicates_dictionary.get(trimmed_word)\n",
    "                correction_dictionary['correction'] = trimmed_word\n",
    "                #print('Input word is: {}, possible match is: {}, {}' \\\n",
    "                 #   .format(original_word, trimmed_word, correction_dictionary))\n",
    "                return correction_dictionary\n",
    "        # If we still didn't get a match after deleteDuplicates,\n",
    "        # then we will use the deleteDuplicates word for more analysis\n",
    "        # if there are trimmed duplicates\n",
    "        if duplicates_dictionary.get(trimmed_word) > 0:\n",
    "            correction_dictionary['repeated_chars'] += duplicates_dictionary.get(trimmed_word)\n",
    "            word = trimmed_word\n",
    "\n",
    "    # Try transpose\n",
    "    \n",
    "    transposes = transpose(word)\n",
    "    for transposed_word in transposes:\n",
    "        if correction(transposed_word) == transposed_word and transposed_word in WORDS:\n",
    "            correction_dictionary['swap_chars'] += 1\n",
    "            correction_dictionary['correction'] = transposed_word\n",
    "            #print('Input word is: {}, possible match is: {}, {}' \\\n",
    "             #   .format(original_word, transposed_word, correction_dictionary))\n",
    "            return correction_dictionary\n",
    "       \n",
    "\n",
    "    # Otherwise, we will match the exact input word\n",
    "    # or the suggested correction of input word\n",
    "    # if it exists in the wordlist\n",
    "    if original_word in WORDS:\n",
    "        correction_dictionary['correction'] = original_word\n",
    "        return correction_dictionary\n",
    "   \n",
    "\n",
    "    \n",
    "    if correction(original_word) in WORDS:\n",
    "        correction_dictionary['correction'] = correction(original_word)\n",
    "        correction_dictionary['symbol_chars'] = 0\n",
    "        correction_dictionary['repeated_chars'] = 0\n",
    "        correction_dictionary['swap_chars'] = 0\n",
    "        correction_dictionary['OOV'] += 1\n",
    "\n",
    "        return correction_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Original_word': 'vi@gra',\n",
       " 'correction': 'viagra',\n",
       " 'symbol_chars': 1,\n",
       " 'repeated_chars': 0,\n",
       " 'swap_chars': 0,\n",
       " 'OOV': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_word('vi@gra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV File Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_correction(csv_filename):\n",
    "    # Read input file and save the list into input_list variable\n",
    "    with open(csv_filename, 'r', encoding='utf-8-sig') as input_file:\n",
    "        try:\n",
    "            input_list = [row[0] for row in csv.reader(input_file)]\n",
    "        except:\n",
    "            print('Error opening input file')\n",
    "\n",
    "    # Save output list\n",
    "    fieldNames = ['Original_word', 'correction', 'symbol_chars', 'repeated_chars', 'swap_chars', 'OOV']\n",
    "    csvfile = open('/home/niddal/Desktop/PhD_projects/Projects/Text_classification/Adversarial_attack/attacks/Offensive-2019/OCR-pipeline-Results/Manuplated/correction/res_15.csv', 'w')\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldNames, delimiter=',')\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Fill the output file\n",
    "    for current_row in input_list:\n",
    "        # If the input is a sentence\n",
    "        if len(current_row.split(' ')) > 1:\n",
    "            sentence_dictionary = {'Original_word': current_row, 'correction': '',\n",
    "                                   'symbol_chars': 0, 'repeated_chars': 0, 'swap_chars': 0, 'OOV': 0}\n",
    "            print('Start of words in \"{}\"'.format(current_row))\n",
    "            for w in current_row.split(' '):\n",
    "                print('***', end='')\n",
    "                word_correction = correct_word(w)\n",
    "                if len(sentence_dictionary['correction']) == 0:\n",
    "                    sentence_dictionary['correction'] = word_correction['correction']\n",
    "                else:\n",
    "                    sentence_dictionary['correction'] += ' ' + word_correction['correction']\n",
    "\n",
    "                sentence_dictionary['symbol_chars'] += word_correction['symbol_chars']\n",
    "                sentence_dictionary['repeated_chars'] += word_correction['repeated_chars']\n",
    "                sentence_dictionary['swap_chars'] += word_correction['swap_chars']\n",
    "                sentence_dictionary['OOV'] += word_correction['OOV']\n",
    "            writer.writerow(sentence_dictionary)\n",
    "            print('End of words in \"{}\"'.format(current_row))\n",
    "        else:\n",
    "            writer.writerow(correct_word(current_row))\n",
    "    csvfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
